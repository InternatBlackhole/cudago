// Code generated by cudago. Edit at your own risk.
package cuda_stuff

import (
    "github.com/InternatBlackhole/cudago/cuda"
	"unsafe"
)


const (
	KeyEdges = "edges"
)


type bordersArgs struct {
    origImage uintptr
    width int32
    height int32
    gradient uintptr
    imgSize int32

}

/*var (
    bordersArgs = bordersArgs{}

)*/







func Borders(grid, block cuda.Dim3, origImage uintptr, width int32, height int32, gradient uintptr, imgSize int32) error {
	err := autoloadLib_edges()
	if err != nil {
		return err
	}
	kern, err := getKernel("edges", "borders")
	if err != nil {
		return err
	}
	params := bordersArgs{
	    origImage: origImage,
	    width: width,
	    height: height,
	    gradient: gradient,
	    imgSize: imgSize,
	
	}
	return kern.Launch(grid, block, unsafe.Pointer(&params.origImage), unsafe.Pointer(&params.width), unsafe.Pointer(&params.height), unsafe.Pointer(&params.gradient), unsafe.Pointer(&params.imgSize))
}

func BordersEx(grid, block cuda.Dim3, sharedMem uint64, stream *cuda.Stream, origImage uintptr, width int32, height int32, gradient uintptr, imgSize int32) error {
	err := autoloadLib_edges()
	if err != nil {
		return err
	}
	kern, err := getKernel("edges", "borders")
	if err != nil {
		return err
	}
	params := bordersArgs{
	    origImage: origImage,
	    width: width,
	    height: height,
	    gradient: gradient,
	    imgSize: imgSize,
	
	}
	return kern.LaunchEx(grid, block, sharedMem, stream, unsafe.Pointer(&params.origImage), unsafe.Pointer(&params.width), unsafe.Pointer(&params.height), unsafe.Pointer(&params.gradient), unsafe.Pointer(&params.imgSize))
}



var loaded_edges = false


func autoloadLib_edges() error {
	if loaded_edges {
		return nil
	}
	err := InitLibrary([]byte(Edges_ptxCode), "edges")
	if err != nil {
		return err
	}
	loaded_edges = true
	return nil
}

const Edges_ptxCode = `//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-34431801
// Cuda compilation tools, release 12.6, V12.6.20
// Based on NVVM 7.0.1
//

.version 8.5
.target sm_52
.address_size 64

	// .globl	borders

.visible .entry borders(
	.param .u64 borders_param_0,
	.param .u32 borders_param_1,
	.param .u32 borders_param_2,
	.param .u64 borders_param_3,
	.param .u32 borders_param_4
)
{
	.reg .pred 	%p<35>;
	.reg .b16 	%rs<9>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<100>;
	.reg .b64 	%rd<13>;


	ld.param.u64 	%rd5, [borders_param_0];
	ld.param.u32 	%r26, [borders_param_1];
	ld.param.u32 	%r27, [borders_param_2];
	ld.param.u64 	%rd6, [borders_param_3];
	ld.param.u32 	%r28, [borders_param_4];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r29, %ctaid.x;
	mov.u32 	%r30, %tid.x;
	mad.lo.s32 	%r2, %r29, %r1, %r30;
	mov.u32 	%r3, %ntid.y;
	mov.u32 	%r31, %ctaid.y;
	mov.u32 	%r32, %tid.y;
	mad.lo.s32 	%r4, %r31, %r3, %r32;
	mul.lo.s32 	%r5, %r4, %r26;
	add.s32 	%r91, %r5, %r2;
	setp.ge.s32 	%p9, %r91, %r28;
	@%p9 bra 	$L__BB0_19;

	cvta.to.global.u64 	%rd7, %rd5;
	add.s32 	%r33, %r2, -1;
	add.s32 	%r34, %r4, -1;
	or.b32  	%r35, %r33, %r34;
	setp.lt.s32 	%p10, %r35, 0;
	setp.gt.s32 	%p11, %r2, %r26;
	or.pred  	%p12, %p11, %p10;
	setp.gt.s32 	%p13, %r4, %r27;
	or.pred  	%p1, %p13, %p12;
	or.b32  	%r36, %r34, %r2;
	setp.lt.s32 	%p14, %r36, 0;
	setp.ge.s32 	%p15, %r2, %r26;
	or.pred  	%p16, %p15, %p14;
	or.pred  	%p2, %p13, %p16;
	add.s32 	%r37, %r2, 1;
	setp.ge.s32 	%p17, %r37, %r26;
	or.b32  	%r38, %r37, %r34;
	setp.lt.s32 	%p18, %r38, 0;
	or.pred  	%p19, %p17, %p18;
	or.pred  	%p3, %p13, %p19;
	sub.s32 	%r39, %r5, %r26;
	add.s32 	%r40, %r39, %r2;
	cvt.s64.s32 	%rd8, %r40;
	add.s64 	%rd1, %rd7, %rd8;
	or.b32  	%r41, %r33, %r4;
	setp.lt.s32 	%p20, %r41, 0;
	or.pred  	%p21, %p11, %p20;
	setp.ge.s32 	%p22, %r4, %r27;
	or.pred  	%p4, %p22, %p21;
	or.b32  	%r42, %r37, %r4;
	setp.lt.s32 	%p23, %r42, 0;
	or.pred  	%p24, %p17, %p23;
	or.pred  	%p5, %p22, %p24;
	add.s32 	%r43, %r5, %r33;
	cvt.s64.s32 	%rd9, %r43;
	add.s64 	%rd2, %rd7, %rd9;
	add.s32 	%r44, %r4, 1;
	or.b32  	%r45, %r33, %r44;
	setp.lt.s32 	%p25, %r45, 0;
	or.pred  	%p26, %p11, %p25;
	setp.ge.s32 	%p27, %r44, %r27;
	or.pred  	%p6, %p27, %p26;
	or.b32  	%r46, %r44, %r2;
	setp.lt.s32 	%p28, %r46, 0;
	or.pred  	%p29, %p15, %p28;
	or.pred  	%p7, %p27, %p29;
	shl.b32 	%r47, %r26, 1;
	add.s32 	%r48, %r39, %r47;
	or.b32  	%r49, %r37, %r44;
	setp.lt.s32 	%p30, %r49, 0;
	or.pred  	%p31, %p17, %p30;
	or.pred  	%p8, %p27, %p31;
	add.s32 	%r50, %r48, %r2;
	cvt.s64.s32 	%rd10, %r50;
	add.s64 	%rd3, %rd7, %rd10;
	mov.u32 	%r51, %nctaid.x;
	mul.lo.s32 	%r52, %r1, %r51;
	mul.lo.s32 	%r53, %r52, %r3;
	mov.u32 	%r54, %nctaid.y;
	mul.lo.s32 	%r7, %r53, %r54;
	cvta.to.global.u64 	%rd4, %rd6;

$L__BB0_2:
	mov.u32 	%r93, 0;
	mov.u32 	%r92, %r93;
	@%p1 bra 	$L__BB0_4;

	ld.global.nc.u8 	%rs1, [%rd1+-1];
	cvt.u32.u16 	%r56, %rs1;
	and.b32  	%r92, %r56, 255;

$L__BB0_4:
	@%p2 bra 	$L__BB0_6;

	ld.global.nc.u8 	%rs2, [%rd1];
	cvt.u32.u16 	%r58, %rs2;
	and.b32  	%r93, %r58, 255;

$L__BB0_6:
	mov.u32 	%r95, 0;
	mov.u32 	%r94, %r95;
	@%p3 bra 	$L__BB0_8;

	ld.global.nc.u8 	%rs3, [%rd1+1];
	cvt.u32.u16 	%r60, %rs3;
	and.b32  	%r94, %r60, 255;

$L__BB0_8:
	@%p4 bra 	$L__BB0_10;

	ld.global.nc.u8 	%rs4, [%rd2];
	cvt.u32.u16 	%r62, %rs4;
	and.b32  	%r95, %r62, 255;

$L__BB0_10:
	mov.u32 	%r97, 0;
	mov.u32 	%r96, %r97;
	@%p5 bra 	$L__BB0_12;

	ld.global.nc.u8 	%rs5, [%rd2+2];
	cvt.u32.u16 	%r64, %rs5;
	and.b32  	%r96, %r64, 255;

$L__BB0_12:
	@%p6 bra 	$L__BB0_14;

	ld.global.nc.u8 	%rs6, [%rd3+-1];
	cvt.u32.u16 	%r66, %rs6;
	and.b32  	%r97, %r66, 255;

$L__BB0_14:
	mov.u32 	%r99, 0;
	mov.u32 	%r98, %r99;
	@%p7 bra 	$L__BB0_16;

	ld.global.nc.u8 	%rs7, [%rd3];
	cvt.u32.u16 	%r68, %rs7;
	and.b32  	%r98, %r68, 255;

$L__BB0_16:
	@%p8 bra 	$L__BB0_18;

	ld.global.nc.u8 	%rs8, [%rd3+1];
	cvt.u32.u16 	%r70, %rs8;
	and.b32  	%r99, %r70, 255;

$L__BB0_18:
	shl.b32 	%r71, %r93, 1;
	add.s32 	%r72, %r71, %r92;
	add.s32 	%r73, %r72, %r94;
	sub.s32 	%r74, %r97, %r73;
	shl.b32 	%r75, %r98, 1;
	add.s32 	%r76, %r74, %r75;
	add.s32 	%r77, %r76, %r99;
	sub.s32 	%r78, %r92, %r94;
	shl.b32 	%r79, %r95, 1;
	add.s32 	%r80, %r78, %r79;
	shl.b32 	%r81, %r96, 1;
	sub.s32 	%r82, %r80, %r81;
	add.s32 	%r83, %r82, %r97;
	sub.s32 	%r84, %r83, %r99;
	mul.lo.s32 	%r85, %r84, %r84;
	mad.lo.s32 	%r86, %r77, %r77, %r85;
	cvt.rn.f32.s32 	%f1, %r86;
	sqrt.rn.f32 	%f2, %f1;
	cvt.rzi.s32.f32 	%r87, %f2;
	setp.lt.s32 	%p32, %r87, 256;
	selp.b32 	%r88, %r87, 0, %p32;
	setp.gt.s32 	%p33, %r87, 255;
	selp.b32 	%r89, 255, 0, %p33;
	or.b32  	%r90, %r88, %r89;
	cvt.s64.s32 	%rd11, %r91;
	add.s64 	%rd12, %rd4, %rd11;
	st.global.u8 	[%rd12], %r90;
	add.s32 	%r91, %r91, %r7;
	setp.lt.s32 	%p34, %r91, %r28;
	@%p34 bra 	$L__BB0_2;

$L__BB0_19:
	ret;

}

`
