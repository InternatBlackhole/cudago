// Code generated by cudago. Edit at your own risk.
package cuda_stuff

import (
    "github.com/InternatBlackhole/cudago/cuda"
	"unsafe"
)


const (
	KeyBitonic_shared_mem = "bitonic_shared_mem"
)


type bitonicsortstartsharedArgs struct {
    a uintptr
    len int32

}
type bitonicsortmiddlesharedArgs struct {
    a uintptr
    len int32
    k int32
    j int32

}
type bitonicsortfinishsharedArgs struct {
    a uintptr
    len int32
    k int32

}

/*var (
    bitonicsortstartsharedArgs = bitonicsortstartsharedArgs{}

    bitonicsortmiddlesharedArgs = bitonicsortmiddlesharedArgs{}

    bitonicsortfinishsharedArgs = bitonicsortfinishsharedArgs{}

)*/







func BitonicSortStartShared(grid, block cuda.Dim3, a uintptr, len int32) error {
	err := autoloadLib_bitonic_shared_mem()
	if err != nil {
		return err
	}
	kern, err := getKernel("bitonic_shared_mem", "bitonicSortStartShared")
	if err != nil {
		return err
	}
	params := bitonicsortstartsharedArgs{
	    a: a,
	    len: len,
	
	}
	return kern.Launch(grid, block, unsafe.Pointer(&params.a), unsafe.Pointer(&params.len))
}

func BitonicSortStartSharedEx(grid, block cuda.Dim3, sharedMem uint64, stream *cuda.Stream, a uintptr, len int32) error {
	err := autoloadLib_bitonic_shared_mem()
	if err != nil {
		return err
	}
	kern, err := getKernel("bitonic_shared_mem", "bitonicSortStartShared")
	if err != nil {
		return err
	}
	params := bitonicsortstartsharedArgs{
	    a: a,
	    len: len,
	
	}
	return kern.LaunchEx(grid, block, sharedMem, stream, unsafe.Pointer(&params.a), unsafe.Pointer(&params.len))
}




func BitonicSortMiddleShared(grid, block cuda.Dim3, a uintptr, len int32, k int32, j int32) error {
	err := autoloadLib_bitonic_shared_mem()
	if err != nil {
		return err
	}
	kern, err := getKernel("bitonic_shared_mem", "bitonicSortMiddleShared")
	if err != nil {
		return err
	}
	params := bitonicsortmiddlesharedArgs{
	    a: a,
	    len: len,
	    k: k,
	    j: j,
	
	}
	return kern.Launch(grid, block, unsafe.Pointer(&params.a), unsafe.Pointer(&params.len), unsafe.Pointer(&params.k), unsafe.Pointer(&params.j))
}

func BitonicSortMiddleSharedEx(grid, block cuda.Dim3, sharedMem uint64, stream *cuda.Stream, a uintptr, len int32, k int32, j int32) error {
	err := autoloadLib_bitonic_shared_mem()
	if err != nil {
		return err
	}
	kern, err := getKernel("bitonic_shared_mem", "bitonicSortMiddleShared")
	if err != nil {
		return err
	}
	params := bitonicsortmiddlesharedArgs{
	    a: a,
	    len: len,
	    k: k,
	    j: j,
	
	}
	return kern.LaunchEx(grid, block, sharedMem, stream, unsafe.Pointer(&params.a), unsafe.Pointer(&params.len), unsafe.Pointer(&params.k), unsafe.Pointer(&params.j))
}




func BitonicSortFinishShared(grid, block cuda.Dim3, a uintptr, len int32, k int32) error {
	err := autoloadLib_bitonic_shared_mem()
	if err != nil {
		return err
	}
	kern, err := getKernel("bitonic_shared_mem", "bitonicSortFinishShared")
	if err != nil {
		return err
	}
	params := bitonicsortfinishsharedArgs{
	    a: a,
	    len: len,
	    k: k,
	
	}
	return kern.Launch(grid, block, unsafe.Pointer(&params.a), unsafe.Pointer(&params.len), unsafe.Pointer(&params.k))
}

func BitonicSortFinishSharedEx(grid, block cuda.Dim3, sharedMem uint64, stream *cuda.Stream, a uintptr, len int32, k int32) error {
	err := autoloadLib_bitonic_shared_mem()
	if err != nil {
		return err
	}
	kern, err := getKernel("bitonic_shared_mem", "bitonicSortFinishShared")
	if err != nil {
		return err
	}
	params := bitonicsortfinishsharedArgs{
	    a: a,
	    len: len,
	    k: k,
	
	}
	return kern.LaunchEx(grid, block, sharedMem, stream, unsafe.Pointer(&params.a), unsafe.Pointer(&params.len), unsafe.Pointer(&params.k))
}



var loaded_bitonic_shared_mem = false


func autoloadLib_bitonic_shared_mem() error {
	if loaded_bitonic_shared_mem {
		return nil
	}
	err := InitLibrary([]byte(Bitonic_shared_mem_ptxCode), "bitonic_shared_mem")
	if err != nil {
		return err
	}
	loaded_bitonic_shared_mem = true
	return nil
}

const Bitonic_shared_mem_ptxCode = `//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-34431801
// Cuda compilation tools, release 12.6, V12.6.20
// Based on NVVM 7.0.1
//

.version 8.5
.target sm_52
.address_size 64

	// .globl	bitonicSortStartShared
.extern .shared .align 16 .b8 as[];

.visible .entry bitonicSortStartShared(
	.param .u64 bitonicSortStartShared_param_0,
	.param .u32 bitonicSortStartShared_param_1
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<42>;
	.reg .b64 	%rd<20>;


	ld.param.u64 	%rd6, [bitonicSortStartShared_param_0];
	ld.param.u32 	%r17, [bitonicSortStartShared_param_1];
	cvta.to.global.u64 	%rd7, %rd6;
	mov.u32 	%r1, %ntid.x;
	shl.b32 	%r2, %r1, 1;
	mov.u32 	%r3, %ctaid.x;
	mul.lo.s32 	%r18, %r2, %r3;
	mov.u32 	%r4, %tid.x;
	add.s32 	%r19, %r18, %r4;
	mul.wide.u32 	%rd8, %r19, 4;
	add.s64 	%rd1, %rd7, %rd8;
	ld.global.u32 	%r20, [%rd1];
	mul.wide.u32 	%rd9, %r4, 4;
	mov.u64 	%rd10, as;
	add.s64 	%rd2, %rd10, %rd9;
	st.shared.u32 	[%rd2], %r20;
	add.s32 	%r21, %r4, %r1;
	add.s32 	%r22, %r21, %r18;
	mul.wide.u32 	%rd11, %r22, 4;
	add.s64 	%rd3, %rd7, %rd11;
	ld.global.u32 	%r41, [%rd3];
	mul.wide.u32 	%rd12, %r21, 4;
	add.s64 	%rd13, %rd10, %rd12;
	st.shared.u32 	[%rd13], %r41;
	setp.eq.s32 	%p1, %r2, 0;
	@%p1 bra 	$L__BB0_12;

	mad.lo.s32 	%r6, %r3, %r1, %r4;
	shr.u32 	%r24, %r17, 31;
	add.s32 	%r25, %r17, %r24;
	shr.s32 	%r7, %r25, 1;
	mov.u32 	%r39, 2;

$L__BB0_2:
	setp.lt.s32 	%p2, %r39, 2;
	@%p2 bra 	$L__BB0_10;

	shr.u32 	%r40, %r39, 1;
	bra.uni 	$L__BB0_4;

$L__BB0_7:
	setp.le.s32 	%p6, %r11, %r12;
	@%p6 bra 	$L__BB0_9;
	bra.uni 	$L__BB0_8;

$L__BB0_4:
	setp.ge.s32 	%p3, %r6, %r7;
	@%p3 bra 	$L__BB0_9;

	shl.b32 	%r26, %r40, 1;
	div.s32 	%r27, %r6, %r40;
	mul.lo.s32 	%r28, %r27, %r40;
	sub.s32 	%r29, %r6, %r28;
	mad.lo.s32 	%r30, %r26, %r27, %r29;
	xor.b32  	%r31, %r30, %r40;
	and.b32  	%r32, %r30, %r39;
	rem.u32 	%r33, %r30, %r1;
	rem.u32 	%r34, %r31, %r1;
	setp.eq.s32 	%p4, %r32, 0;
	mul.wide.s32 	%rd14, %r33, 4;
	add.s64 	%rd4, %rd10, %rd14;
	ld.shared.u32 	%r11, [%rd4];
	mul.wide.s32 	%rd16, %r34, 4;
	add.s64 	%rd5, %rd10, %rd16;
	ld.shared.u32 	%r12, [%rd5];
	@%p4 bra 	$L__BB0_7;

	setp.lt.s32 	%p5, %r11, %r12;
	@%p5 bra 	$L__BB0_8;
	bra.uni 	$L__BB0_9;

$L__BB0_8:
	st.shared.u32 	[%rd4], %r12;
	st.shared.u32 	[%rd5], %r11;

$L__BB0_9:
	bar.sync 	0;
	shr.u32 	%r40, %r40, 1;
	setp.ne.s32 	%p7, %r40, 0;
	@%p7 bra 	$L__BB0_4;

$L__BB0_10:
	shl.b32 	%r39, %r39, 1;
	setp.le.u32 	%p8, %r39, %r2;
	@%p8 bra 	$L__BB0_2;

	ld.shared.u32 	%r41, [%rd13];

$L__BB0_12:
	ld.shared.u32 	%r38, [%rd2];
	st.global.u32 	[%rd1], %r38;
	st.global.u32 	[%rd3], %r41;
	ret;

}
	// .globl	bitonicSortMiddleShared
.visible .entry bitonicSortMiddleShared(
	.param .u64 bitonicSortMiddleShared_param_0,
	.param .u32 bitonicSortMiddleShared_param_1,
	.param .u32 bitonicSortMiddleShared_param_2,
	.param .u32 bitonicSortMiddleShared_param_3
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<20>;
	.reg .b64 	%rd<7>;


	ld.param.u64 	%rd3, [bitonicSortMiddleShared_param_0];
	ld.param.u32 	%r4, [bitonicSortMiddleShared_param_2];
	ld.param.u32 	%r5, [bitonicSortMiddleShared_param_3];
	mov.u32 	%r6, %ntid.x;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r1, %r7, %r6, %r8;
	ld.param.u32 	%r9, [bitonicSortMiddleShared_param_1];
	shr.u32 	%r10, %r9, 31;
	add.s32 	%r11, %r9, %r10;
	shr.s32 	%r12, %r11, 1;
	setp.ge.s32 	%p1, %r1, %r12;
	@%p1 bra 	$L__BB1_5;

	cvta.to.global.u64 	%rd4, %rd3;
	shl.b32 	%r13, %r5, 1;
	div.s32 	%r14, %r1, %r5;
	mul.lo.s32 	%r15, %r14, %r5;
	sub.s32 	%r16, %r1, %r15;
	mad.lo.s32 	%r17, %r13, %r14, %r16;
	xor.b32  	%r18, %r17, %r5;
	and.b32  	%r19, %r17, %r4;
	setp.eq.s32 	%p2, %r19, 0;
	mul.wide.s32 	%rd5, %r17, 4;
	add.s64 	%rd1, %rd4, %rd5;
	ld.global.u32 	%r2, [%rd1];
	mul.wide.s32 	%rd6, %r18, 4;
	add.s64 	%rd2, %rd4, %rd6;
	ld.global.u32 	%r3, [%rd2];
	@%p2 bra 	$L__BB1_3;

	setp.lt.s32 	%p3, %r2, %r3;
	@%p3 bra 	$L__BB1_4;
	bra.uni 	$L__BB1_5;

$L__BB1_4:
	st.global.u32 	[%rd1], %r3;
	st.global.u32 	[%rd2], %r2;

$L__BB1_5:
	ret;

$L__BB1_3:
	setp.le.s32 	%p4, %r2, %r3;
	@%p4 bra 	$L__BB1_5;
	bra.uni 	$L__BB1_4;

}
	// .globl	bitonicSortFinishShared
.visible .entry bitonicSortFinishShared(
	.param .u64 bitonicSortFinishShared_param_0,
	.param .u32 bitonicSortFinishShared_param_1,
	.param .u32 bitonicSortFinishShared_param_2
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<35>;
	.reg .b64 	%rd<17>;


	ld.param.u64 	%rd7, [bitonicSortFinishShared_param_0];
	ld.param.u32 	%r14, [bitonicSortFinishShared_param_1];
	ld.param.u32 	%r15, [bitonicSortFinishShared_param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	mov.u32 	%r1, %ntid.x;
	shl.b32 	%r33, %r1, 1;
	mov.u32 	%r3, %ctaid.x;
	mul.lo.s32 	%r16, %r33, %r3;
	mov.u32 	%r4, %tid.x;
	add.s32 	%r17, %r16, %r4;
	mul.wide.u32 	%rd9, %r17, 4;
	add.s64 	%rd1, %rd8, %rd9;
	ld.global.u32 	%r18, [%rd1];
	mul.wide.u32 	%rd10, %r4, 4;
	mov.u64 	%rd11, as;
	add.s64 	%rd2, %rd11, %rd10;
	st.shared.u32 	[%rd2], %r18;
	add.s32 	%r19, %r4, %r1;
	add.s32 	%r20, %r19, %r16;
	mul.wide.u32 	%rd12, %r20, 4;
	add.s64 	%rd3, %rd8, %rd12;
	ld.global.u32 	%r34, [%rd3];
	mul.wide.u32 	%rd13, %r19, 4;
	add.s64 	%rd4, %rd11, %rd13;
	st.shared.u32 	[%rd4], %r34;
	setp.lt.s32 	%p1, %r33, 1;
	@%p1 bra 	$L__BB2_9;

	mad.lo.s32 	%r6, %r3, %r1, %r4;
	shr.u32 	%r21, %r14, 31;
	add.s32 	%r22, %r14, %r21;
	shr.s32 	%r7, %r22, 1;
	bra.uni 	$L__BB2_2;

$L__BB2_5:
	setp.le.s32 	%p5, %r9, %r10;
	@%p5 bra 	$L__BB2_7;
	bra.uni 	$L__BB2_6;

$L__BB2_2:
	setp.ge.s32 	%p2, %r6, %r7;
	@%p2 bra 	$L__BB2_7;

	shl.b32 	%r23, %r33, 1;
	div.s32 	%r24, %r6, %r33;
	mul.lo.s32 	%r25, %r24, %r33;
	sub.s32 	%r26, %r6, %r25;
	mad.lo.s32 	%r27, %r23, %r24, %r26;
	xor.b32  	%r28, %r27, %r33;
	and.b32  	%r29, %r27, %r15;
	rem.u32 	%r30, %r27, %r1;
	rem.u32 	%r31, %r28, %r1;
	setp.eq.s32 	%p3, %r29, 0;
	mul.wide.s32 	%rd14, %r30, 4;
	add.s64 	%rd5, %rd11, %rd14;
	ld.shared.u32 	%r9, [%rd5];
	mul.wide.s32 	%rd16, %r31, 4;
	add.s64 	%rd6, %rd11, %rd16;
	ld.shared.u32 	%r10, [%rd6];
	@%p3 bra 	$L__BB2_5;

	setp.lt.s32 	%p4, %r9, %r10;
	@%p4 bra 	$L__BB2_6;
	bra.uni 	$L__BB2_7;

$L__BB2_6:
	st.shared.u32 	[%rd5], %r10;
	st.shared.u32 	[%rd6], %r9;

$L__BB2_7:
	bar.sync 	0;
	shr.u32 	%r33, %r33, 1;
	setp.ne.s32 	%p6, %r33, 0;
	@%p6 bra 	$L__BB2_2;

	ld.shared.u32 	%r34, [%rd4];

$L__BB2_9:
	ld.shared.u32 	%r32, [%rd2];
	st.global.u32 	[%rd1], %r32;
	st.global.u32 	[%rd3], %r34;
	ret;

}

`
